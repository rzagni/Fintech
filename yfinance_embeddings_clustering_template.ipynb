{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rzagni/Fintech/blob/main/yfinance_embeddings_clustering_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "278363b3",
      "metadata": {
        "id": "278363b3"
      },
      "source": [
        "# Introduction to text embeddings on S&P 500 news"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83d6ffde",
      "metadata": {
        "id": "83d6ffde"
      },
      "source": [
        "objectives# 📌 Objectives\n",
        "\n",
        "By the end of this notebook, students will be able to:\n",
        "\n",
        "1. **Retrieve Financial News:**\n",
        "   - Use the `yfinance` library to gather news headlines for all companies in the S&P 500 index.\n",
        "\n",
        "2. **Clean and Structure Financial Text Data:**\n",
        "   - Extract and organize relevant metadata (e.g., ticker, title, summary, publication date, URL) into a structured pandas DataFrame.\n",
        "\n",
        "3. **Generate Text Embeddings:**\n",
        "   - Apply a pre-trained sentence transformer model (`all-MiniLM-L6-v2`) to convert news headlines and summaries into numerical embeddings.\n",
        "\n",
        "4. **Apply Clustering Techniques:**\n",
        "   - Use K-Means clustering to identify groups of similar news articles based on semantic content.\n",
        "\n",
        "5. **Determine Optimal Number of Clusters:**\n",
        "   - Evaluate clustering quality using silhouette scores to find the best number of clusters.\n",
        "\n",
        "6. **Visualize High-Dimensional Embeddings:**\n",
        "   - Reduce the embedding space using PCA and visualize clusters in two dimensions.\n",
        "\n",
        "7. **Interpret Cluster Themes:**\n",
        "   - Analyze representative news\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe54247f",
      "metadata": {
        "id": "fe54247f"
      },
      "source": [
        "## Install and Import important librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "49c4fff2",
      "metadata": {
        "id": "49c4fff2",
        "outputId": "3624d6ac-046f-4d9a-a5f0-f06d585d7fe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.65)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.8)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.1)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.7.14)\n",
            "Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m470.2/470.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 4.1.0\n",
            "    Uninstalling sentence-transformers-4.1.0:\n",
            "      Successfully uninstalled sentence-transformers-4.1.0\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sentence-transformers-5.0.0\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas\n",
        "%pip install yfinance\n",
        "%pip install lxml\n",
        "%pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7b8b20aa",
      "metadata": {
        "id": "7b8b20aa"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f54a285",
      "metadata": {
        "id": "3f54a285"
      },
      "source": [
        "## Get the list of stocks in the S&P 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2d3c3175",
      "metadata": {
        "id": "2d3c3175",
        "outputId": "3056f3b5-08ca-4b55-e936-2b60848a5b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Symbol             Security             GICS Sector  \\\n",
              "0    MMM                   3M             Industrials   \n",
              "1    AOS          A. O. Smith             Industrials   \n",
              "2    ABT  Abbott Laboratories             Health Care   \n",
              "3   ABBV               AbbVie             Health Care   \n",
              "4    ACN            Accenture  Information Technology   \n",
              "\n",
              "                GICS Sub-Industry    Headquarters Location  Date added  \\\n",
              "0        Industrial Conglomerates    Saint Paul, Minnesota  1957-03-04   \n",
              "1               Building Products     Milwaukee, Wisconsin  2017-07-26   \n",
              "2           Health Care Equipment  North Chicago, Illinois  1957-03-04   \n",
              "3                   Biotechnology  North Chicago, Illinois  2012-12-31   \n",
              "4  IT Consulting & Other Services          Dublin, Ireland  2011-07-06   \n",
              "\n",
              "       CIK      Founded  \n",
              "0    66740         1902  \n",
              "1    91142         1916  \n",
              "2     1800         1888  \n",
              "3  1551152  2013 (1888)  \n",
              "4  1467373         1989  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7264b3c6-3b87-4cbf-9d0c-976bbc9ddae0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Symbol</th>\n",
              "      <th>Security</th>\n",
              "      <th>GICS Sector</th>\n",
              "      <th>GICS Sub-Industry</th>\n",
              "      <th>Headquarters Location</th>\n",
              "      <th>Date added</th>\n",
              "      <th>CIK</th>\n",
              "      <th>Founded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MMM</td>\n",
              "      <td>3M</td>\n",
              "      <td>Industrials</td>\n",
              "      <td>Industrial Conglomerates</td>\n",
              "      <td>Saint Paul, Minnesota</td>\n",
              "      <td>1957-03-04</td>\n",
              "      <td>66740</td>\n",
              "      <td>1902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AOS</td>\n",
              "      <td>A. O. Smith</td>\n",
              "      <td>Industrials</td>\n",
              "      <td>Building Products</td>\n",
              "      <td>Milwaukee, Wisconsin</td>\n",
              "      <td>2017-07-26</td>\n",
              "      <td>91142</td>\n",
              "      <td>1916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ABT</td>\n",
              "      <td>Abbott Laboratories</td>\n",
              "      <td>Health Care</td>\n",
              "      <td>Health Care Equipment</td>\n",
              "      <td>North Chicago, Illinois</td>\n",
              "      <td>1957-03-04</td>\n",
              "      <td>1800</td>\n",
              "      <td>1888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ABBV</td>\n",
              "      <td>AbbVie</td>\n",
              "      <td>Health Care</td>\n",
              "      <td>Biotechnology</td>\n",
              "      <td>North Chicago, Illinois</td>\n",
              "      <td>2012-12-31</td>\n",
              "      <td>1551152</td>\n",
              "      <td>2013 (1888)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ACN</td>\n",
              "      <td>Accenture</td>\n",
              "      <td>Information Technology</td>\n",
              "      <td>IT Consulting &amp; Other Services</td>\n",
              "      <td>Dublin, Ireland</td>\n",
              "      <td>2011-07-06</td>\n",
              "      <td>1467373</td>\n",
              "      <td>1989</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7264b3c6-3b87-4cbf-9d0c-976bbc9ddae0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7264b3c6-3b87-4cbf-9d0c-976bbc9ddae0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7264b3c6-3b87-4cbf-9d0c-976bbc9ddae0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cf6c4777-82ae-4cc3-93ae-bba252e0a29f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf6c4777-82ae-4cc3-93ae-bba252e0a29f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cf6c4777-82ae-4cc3-93ae-bba252e0a29f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_tickers\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Symbol\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"AOS\",\n          \"ACN\",\n          \"ABT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Security\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"A. O. Smith\",\n          \"Accenture\",\n          \"Abbott Laboratories\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GICS Sector\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Industrials\",\n          \"Health Care\",\n          \"Information Technology\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GICS Sub-Industry\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Building Products\",\n          \"IT Consulting & Other Services\",\n          \"Health Care Equipment\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Headquarters Location\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Milwaukee, Wisconsin\",\n          \"Dublin, Ireland\",\n          \"Saint Paul, Minnesota\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date added\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"2017-07-26\",\n          \"2011-07-06\",\n          \"1957-03-04\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CIK\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 798720,\n        \"min\": 1800,\n        \"max\": 1551152,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          91142,\n          1467373,\n          1800\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Founded\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"1916\",\n          \"1989\",\n          \"1888\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Read and print the stock tickers that make up S&P500\n",
        "df_tickers = pd.read_html(\n",
        "    'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
        "\n",
        "display(df_tickers.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c5309ff2",
      "metadata": {
        "id": "c5309ff2"
      },
      "outputs": [],
      "source": [
        "# Convert ticker symbols to list for next processing steps\n",
        "ticker_list = df_tickers['Symbol'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e067dba6",
      "metadata": {
        "id": "e067dba6"
      },
      "source": [
        "## Get the news of all 500 stocks in the S&P 500 Index\n",
        "Use the yfinance library to retrieve the news of all 500 stocks in the index.\n",
        "https://ranaroussi.github.io/yfinance/reference/yfinance.stock.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2807119",
      "metadata": {
        "id": "c2807119"
      },
      "source": [
        "### Get the news in a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2e78bb43",
      "metadata": {
        "id": "2e78bb43"
      },
      "outputs": [],
      "source": [
        "def get_news(ticker_list, news_dict=None, max_attempts=10, delay=0.5):\n",
        "    \"\"\"\n",
        "    Get financial news for a list of stock tickers using yfinance.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ticker_list : list of str\n",
        "        List of stock ticker symbols to fetch news for.\n",
        "    news_dict : dict, optional\n",
        "        Existing dictionary of previously fetched news.\n",
        "    max_attempts : int, default=10\n",
        "        Maximum retry attempts for failed tickers.\n",
        "    delay : float, default=0.5\n",
        "        Delay in seconds between API calls.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    news_dict : dict\n",
        "        Dictionary mapping tickers to lists of news articles.\n",
        "    remaining : list of str\n",
        "        Tickers that still failed after all retry attempts.\n",
        "    \"\"\"\n",
        "    if news_dict is None:\n",
        "        news_dict = {}\n",
        "\n",
        "    remaining = ticker_list.copy()\n",
        "    attempt = 1\n",
        "\n",
        "    while remaining and attempt <= max_attempts:\n",
        "        failed = []\n",
        "        total = len(remaining)\n",
        "\n",
        "        for idx, ticker in enumerate(remaining, 1):\n",
        "            clear_output(wait=True)\n",
        "            print(f\"[Attempt {attempt}] Processing: {ticker}\")\n",
        "            print(f\"Processed: {idx} of {total} | Errors: {len(failed)}\")\n",
        "\n",
        "            try:\n",
        "                stock = yf.Ticker(ticker)\n",
        "                news = stock.news\n",
        "                if news is None:\n",
        "                    raise ValueError(\"yfinance returned None for news\")\n",
        "\n",
        "                news_dict[ticker] = news\n",
        "            except Exception as e:\n",
        "                failed.append(ticker)\n",
        "\n",
        "            time.sleep(delay)\n",
        "\n",
        "        print(f\"\\nAttempt {attempt} complete. {len(failed)} tickers failed.\\n\")\n",
        "\n",
        "        if not failed:\n",
        "            break\n",
        "\n",
        "        remaining = failed\n",
        "        attempt += 1\n",
        "\n",
        "    return news_dict, remaining\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_dict, still_failed = get_news(ticker_list)\n",
        "\n",
        "if still_failed:\n",
        "    print(f\"Tickers failed after retries: {still_failed}\")\n",
        "else:\n",
        "    print(\"All tickers processed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJsr8gNUtFAr",
        "outputId": "ed2da2d1-64bc-4625-bf02-1972e159b221"
      },
      "id": "qJsr8gNUtFAr",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Attempt 1] Processing: ZTS\n",
            "Processed: 502 of 502 | Errors: 0\n",
            "\n",
            "Attempt 1 complete. 0 tickers failed.\n",
            "\n",
            "Tickers failed after retries: ['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A', 'APD', 'ABNB', 'AKAM', 'ALB', 'ARE', 'ALGN', 'ALLE', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AMCR', 'AEE', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'AME', 'AMGN', 'APH', 'ADI', 'AON', 'APA', 'APO', 'AAPL', 'AMAT', 'APTV', 'ACGL', 'ADM', 'ANET', 'AJG', 'AIZ', 'T', 'ATO', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'AXON', 'BKR', 'BALL', 'BAC', 'BAX', 'BDX', 'BRK.B', 'BBY', 'TECH', 'BIIB', 'BLK', 'BX', 'BK', 'BA', 'BKNG', 'BSX', 'BMY', 'AVGO', 'BR', 'BRO', 'BF.B', 'BLDR', 'BG', 'BXP', 'CHRW', 'CDNS', 'CZR', 'CPT', 'CPB', 'COF', 'CAH', 'KMX', 'CCL', 'CARR', 'CAT', 'CBOE', 'CBRE', 'CDW', 'COR', 'CNC', 'CNP', 'CF', 'CRL', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CLX', 'CME', 'CMS', 'KO', 'CTSH', 'COIN', 'CL', 'CMCSA', 'CAG', 'COP', 'ED', 'STZ', 'CEG', 'COO', 'CPRT', 'GLW', 'CPAY', 'CTVA', 'CSGP', 'COST', 'CTRA', 'CRWD', 'CCI', 'CSX', 'CMI', 'CVS', 'DHR', 'DRI', 'DDOG', 'DVA', 'DAY', 'DECK', 'DE', 'DELL', 'DAL', 'DVN', 'DXCM', 'FANG', 'DLR', 'DG', 'DLTR', 'D', 'DPZ', 'DASH', 'DOV', 'DOW', 'DHI', 'DTE', 'DUK', 'DD', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'ELV', 'EMR', 'ENPH', 'ETR', 'EOG', 'EPAM', 'EQT', 'EFX', 'EQIX', 'EQR', 'ERIE', 'ESS', 'EL', 'EG', 'EVRG', 'ES', 'EXC', 'EXE', 'EXPE', 'EXPD', 'EXR', 'XOM', 'FFIV', 'FDS', 'FICO', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FSLR', 'FE', 'FI', 'F', 'FTNT', 'FTV', 'FOXA', 'FOX', 'BEN', 'FCX', 'GRMN', 'IT', 'GE', 'GEHC', 'GEV', 'GEN', 'GNRC', 'GD', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GL', 'GDDY', 'GS', 'HAL', 'HIG', 'HAS', 'HCA', 'DOC', 'HSIC', 'HSY', 'HPE', 'HLT', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HWM', 'HPQ', 'HUBB', 'HUM', 'HBAN', 'HII', 'IBM', 'IEX', 'IDXX', 'ITW', 'INCY', 'IR', 'PODD', 'INTC', 'ICE', 'IFF', 'IP', 'IPG', 'INTU', 'ISRG', 'IVZ', 'INVH', 'IQV', 'IRM', 'JBHT', 'JBL', 'JKHY', 'J', 'JNJ', 'JCI', 'JPM', 'K', 'KVUE', 'KDP', 'KEY', 'KEYS', 'KMB', 'KIM', 'KMI', 'KKR', 'KLAC', 'KHC', 'KR', 'LHX', 'LH', 'LRCX', 'LW', 'LVS', 'LDOS', 'LEN', 'LII', 'LLY', 'LIN', 'LYV', 'LKQ', 'LMT', 'L', 'LOW', 'LULU', 'LYB', 'MTB', 'MPC', 'MKTX', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MTCH', 'MKC', 'MCD', 'MCK', 'MDT', 'MRK', 'META', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MRNA', 'MHK', 'MOH', 'TAP', 'MDLZ', 'MPWR', 'MNST', 'MCO', 'MS', 'MOS', 'MSI', 'MSCI', 'NDAQ', 'NTAP', 'NFLX', 'NEM', 'NWSA', 'NWS', 'NEE', 'NKE', 'NI', 'NDSN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'NVR', 'NXPI', 'ORLY', 'OXY', 'ODFL', 'OMC', 'ON', 'OKE', 'ORCL', 'OTIS', 'PCAR', 'PKG', 'PLTR', 'PANW', 'PARA', 'PH', 'PAYX', 'PAYC', 'PYPL', 'PNR', 'PEP', 'PFE', 'PCG', 'PM', 'PSX', 'PNW', 'PNC', 'POOL', 'PPG', 'PPL', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PTC', 'PSA', 'PHM', 'PWR', 'QCOM', 'DGX', 'RL', 'RJF', 'RTX', 'O', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RVTY', 'ROK', 'ROL', 'ROP', 'ROST', 'RCL', 'SPGI', 'CRM', 'SBAC', 'SLB', 'STX', 'SRE', 'NOW', 'SHW', 'SPG', 'SWKS', 'SJM', 'SW', 'SNA', 'SOLV', 'SO', 'LUV', 'SWK', 'SBUX', 'STT', 'STLD', 'STE', 'SYK', 'SMCI', 'SYF', 'SNPS', 'SYY', 'TMUS', 'TROW', 'TTWO', 'TPR', 'TRGP', 'TGT', 'TEL', 'TDY', 'TER', 'TSLA', 'TXN', 'TPL', 'TXT', 'TMO', 'TJX', 'TKO', 'TTD', 'TSCO', 'TT', 'TDG', 'TRV', 'TRMB', 'TFC', 'TYL', 'TSN', 'USB', 'UBER', 'UDR', 'ULTA', 'UNP', 'UAL', 'UPS', 'URI', 'UNH', 'UHS', 'VLO', 'VTR', 'VLTO', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VTRS', 'VICI', 'V', 'VST', 'VMC', 'WRB', 'GWW', 'WAB', 'WBA', 'WMT', 'DIS', 'WBD', 'WM', 'WAT', 'WEC', 'WFC', 'WELL', 'WST', 'WDC', 'WY', 'WSM', 'WMB', 'WTW', 'WDAY', 'WYNN', 'XEL', 'XYL', 'YUM', 'ZBRA', 'ZBH', 'ZTS']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHECK WHY 502 INSTEAD OF 503"
      ],
      "metadata": {
        "id": "5rqE1QA11Iem"
      },
      "id": "5rqE1QA11Iem"
    },
    {
      "cell_type": "markdown",
      "id": "c1de6cae",
      "metadata": {
        "id": "c1de6cae"
      },
      "source": [
        "### Structure the news into a pandas dataframe\n",
        "\n",
        "Your final dataframe should have the following columns:\n",
        "- TICKER\n",
        "- TITLE (of the news)\n",
        "- SUMMARY (of the news)\n",
        "- PUBLICATION_DATE (of the news)\n",
        "- URL (of the news)\n",
        "\n",
        "Note: all of those fields are provided in the yfinance news component. Refer to the library documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fdb2faf1",
      "metadata": {
        "id": "fdb2faf1"
      },
      "outputs": [],
      "source": [
        "rows = []\n",
        "\n",
        "for ticker, articles in news_dict.items():\n",
        "    if not articles:\n",
        "        continue\n",
        "\n",
        "    for article in articles:\n",
        "        content = article.get('content') or {}\n",
        "\n",
        "        title = content.get('title', '').strip()\n",
        "        summary = content.get('summary', '').strip()\n",
        "\n",
        "        url = (\n",
        "            (content.get('clickThroughUrl') or {}).get('url') or\n",
        "            content.get('previewUrl') or\n",
        "            (content.get('canonicalUrl') or {}).get('url') or\n",
        "            ''\n",
        "        ).strip()\n",
        "\n",
        "        pub_date_str = content.get('pubDate', '').strip()\n",
        "        try:\n",
        "            pub_date = datetime.strptime(pub_date_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "            formatted_date = pub_date.strftime('%d-%b-%y')\n",
        "        except Exception:\n",
        "            formatted_date = ''\n",
        "\n",
        "        if not any([title, summary, formatted_date, url]):\n",
        "            continue  # skip this article\n",
        "\n",
        "        rows.append({\n",
        "            'TICKER': ticker,\n",
        "            'TITLE': title,\n",
        "            'SUMMARY': summary,\n",
        "            'PUBLICATION_DATE': formatted_date,\n",
        "            'URL': url\n",
        "        })\n",
        "\n",
        "df_news = pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Review the first 5 articles\n",
        "df_news.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "wiAAX_zM6HNG",
        "outputId": "ff158872-2fb5-4220-c2bd-4fc61db38131"
      },
      "id": "wiAAX_zM6HNG",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_news' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-1864747982.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Review the first 5 articles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_news\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_news' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7d157a8",
      "metadata": {
        "id": "c7d157a8"
      },
      "source": [
        "## Exploring text embeddings\n",
        "\n",
        "- Use the open-source model: 'sentence-transformers/all-MiniLM-L6-v2' to create embeddings on the news title and summary\n",
        "- You should combine the title and summary into one string that you will embed together\n",
        "- Add a column to your news dataframe called EMBEDDED_TEXT using ONLY the TITLE of the news\n",
        "- Add a column to your news dataframe called EMBEDDINGS, which contains the embedding of EMBEDDED_TEXT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a59b6d58",
      "metadata": {
        "id": "a59b6d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "bacc4402-0926-4d4e-c1dd-6ac60e8bebd1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SentenceTransformer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-1162147201.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading the pre-trained embedding model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentence-transformers/all-MiniLM-L6-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Combining TITLE and SUMMARY into a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m df_news['EMBEDDED_TEXT'] = (\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SentenceTransformer' is not defined"
          ]
        }
      ],
      "source": [
        "# Loading the pre-trained embedding model\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Combining TITLE and SUMMARY into a string\n",
        "df_news['EMBEDDED_TEXT'] = (\n",
        "    df_news['TITLE'].fillna('') + ' ' + df_news['SUMMARY'].fillna('')\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_news['EMBEDDED_TEXT'][5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "xu1CxMY67xfp",
        "outputId": "4c562eb4-65c2-48a1-cddb-0ba184bc0a76"
      },
      "id": "xu1CxMY67xfp",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3M Gives Investors a ‘Beat and Raise.’ The Stock Is Rising.. 3M  traded higher initially after reporting better-than-expected second-quarter earnings, but gave up gains throughout the day.  Wall Street was looking for earnings per share of $2.01 on sales of $6.1 billion, according to FactSet.  “We delivered strong results in the second quarter, posting positive organic sales growth and double-digit EPS growth,” said CEO William Brown in a news release.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings\n",
        "embeddings = model.encode(df_news['EMBEDDED_TEXT'].tolist(), show_progress_bar=True)\n",
        "\n",
        "# Store embeddings in the DataFrame\n",
        "df_news['EMBEDDINGS'] = embeddings.tolist()"
      ],
      "metadata": {
        "id": "fZcqoVy_7aqb"
      },
      "id": "fZcqoVy_7aqb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "17f0fada",
      "metadata": {
        "id": "17f0fada"
      },
      "source": [
        "## Using K-means clustering on news embeddings\n",
        "to simplify, keep only one news for each company (ticker), you should have 500 rows in your news dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78bf32c0",
      "metadata": {
        "id": "78bf32c0"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# USE AS MANY CELLS AS YOU NEED\n",
        "# MAKE SURE TO DISPLAY INTERMEDIARY RESULS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1cdc413",
      "metadata": {
        "id": "b1cdc413"
      },
      "source": [
        "### Identify the number of clusters using the silhouette score\n",
        "\n",
        "- Using a for loop, do the clustering with different k values (number of clusters), test 1 to 6 clusters\n",
        "- Compute the silhouette score for every k value\n",
        "- Plot the silhouette score for different k values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22bda120",
      "metadata": {
        "id": "22bda120"
      },
      "source": [
        "#### Try different values of k and compute silhouette scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ea69df",
      "metadata": {
        "id": "e0ea69df"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# USE AS MANY CELLS AS YOU NEED\n",
        "# MAKE SURE TO DISPLAY INTERMEDIARY RESULS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41da4eae",
      "metadata": {
        "id": "41da4eae"
      },
      "source": [
        "#### Plot silhouette scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99798590",
      "metadata": {
        "id": "99798590"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# USE AS MANY CELLS AS YOU NEED\n",
        "# MAKE SURE TO DISPLAY INTERMEDIARY RESULS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d311d914",
      "metadata": {
        "id": "d311d914"
      },
      "source": [
        "#### Identify the Best k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34e71c10",
      "metadata": {
        "id": "34e71c10"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# USE AS MANY CELLS AS YOU NEED\n",
        "# MAKE SURE TO DISPLAY INTERMEDIARY RESULS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07115a68",
      "metadata": {
        "id": "07115a68"
      },
      "source": [
        "#### Cluster the embeddings using 3 clusters (k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bbae044",
      "metadata": {
        "id": "3bbae044"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# USE AS MANY CELLS AS YOU NEED\n",
        "# MAKE SURE TO DISPLAY INTERMEDIARY RESULS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4920b80",
      "metadata": {
        "id": "c4920b80"
      },
      "source": [
        "### Visualize the 2 first PCA Components of your embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e600ab9",
      "metadata": {
        "id": "5e600ab9"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# USE AS MANY CELLS AS YOU NEED\n",
        "# MAKE SURE TO DISPLAY INTERMEDIARY RESULS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b0dae3d",
      "metadata": {
        "id": "6b0dae3d"
      },
      "source": [
        "#### Analyze the content of each cluster\n",
        "- Add the kmeans cluster label to your news dataframe\n",
        "- Print the content of each cluster and analyze it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e6719b8",
      "metadata": {
        "id": "3e6719b8"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# USE AS MANY CELLS AS YOU NEED\n",
        "# MAKE SURE TO DISPLAY INTERMEDIARY RESULS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c8297d",
      "metadata": {
        "id": "f7c8297d"
      },
      "source": [
        "## Question section\n",
        "Take time to reflect on what you've implemented and observed. Answer the following questions in a separate markdown cell or notebook file:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02f469b0",
      "metadata": {
        "id": "02f469b0"
      },
      "source": [
        "### Technical Understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efdb028a",
      "metadata": {
        "id": "efdb028a"
      },
      "source": [
        "#### How does the `SentenceTransformer` model convert text into embeddings? What kind of information do you think is captured in these embeddings?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d354724",
      "metadata": {
        "id": "0d354724"
      },
      "source": [
        "YOUR WRITTEN RESPONSE HERE\n",
        "\n",
        "SentenceTransformer uses transformer-based models (like BERT or its variants) to convert input text into fixed-size dense vector representations. These embeddings capture semantic meaning — not just word presence, but also context, syntax, and relationships. For example, the sentences “Apple stock is rising” and “Shares of Apple are going up” would have similar embeddings because they convey the same meaning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3db117bb",
      "metadata": {
        "id": "3db117bb"
      },
      "source": [
        "#### Why do we use the combination of TITLE and SUMMARY instead of just one or the other?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a8d7c18",
      "metadata": {
        "id": "7a8d7c18"
      },
      "source": [
        "YOUR WRITTEN RESONSE HERE\n",
        "\n",
        "Combining both fields provides a richer representation of the news item. Titles are usually concise and attention-grabbing, while summaries offer more detail. Together, they create a more informative embedding, improving clustering and analysis accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06502464",
      "metadata": {
        "id": "06502464"
      },
      "source": [
        "#### Explain what the silhouette score represents and how it helped you determine the number of clusters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aab87ec5",
      "metadata": {
        "id": "aab87ec5"
      },
      "source": [
        "YOUR WRITTEN RESPONSE HERE\n",
        "\n",
        "The silhouette score measures how similar a data point is to its own cluster compared to other clusters. It ranges from -1 (bad clustering) to 1 (good clustering). By computing this score across different k values, we can select the value of k that maximizes this score — indicating that data points are well matched to their own cluster and clearly separated from others."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e47ff9ae",
      "metadata": {
        "id": "e47ff9ae"
      },
      "source": [
        "### Data Analysis and Interpretation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe370e5a",
      "metadata": {
        "id": "fe370e5a"
      },
      "source": [
        "#### After assigning cluster labels, did you notice any thematic consistency within clusters? For each cluster, is there a main theme? Is there a tone or a function behind the news? Is there a specific content source type?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aabc96f",
      "metadata": {
        "id": "1aabc96f"
      },
      "source": [
        "YOUR WRITTEN RESPONSE HERE\n",
        "\n",
        "Cluster 0\n",
        "- Main Theme: Traditional financial updates, dividends, valuation\n",
        "- Tone / Function: Neutral, technical, investor-oriented\n",
        "- Content Source Type: Bloomberg/Zacks-like institutional coverage\n",
        "\n",
        "\n",
        "Cluster 1\n",
        "- Main Theme: Investment advice, AI/growth picks, strategy\n",
        "- Tone / Function: Prescriptive, opportunity-seeking\n",
        "- Content Source Type: Blogs, analyst columns, financial YouTube\n",
        "\n",
        "Cluster 2\n",
        "- Main Theme: Market-moving events, macro risk, legal/political\n",
        "- Tone / Function: News-driven, broader & narrative\n",
        "- Content Source Type: Newswires, macro reporting, investigative"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02f5a79b",
      "metadata": {
        "id": "02f5a79b"
      },
      "source": [
        "#### Were there clusters that seemed too broad or too specific? What might cause this in your data?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a0e4c94",
      "metadata": {
        "id": "1a0e4c94"
      },
      "source": [
        "YOUR WRITTEN RESPONSE HERE\n",
        "\n",
        "Cluster 0 – Relatively Well-Defined and Focused\n",
        "\n",
        "Why? Most items are traditional financial disclosures — earnings reports, dividends, valuations, analyst revisions. The cluster is primarily descriptive and numeric.\n",
        "Result: Probably the most specific and cleanest cluster. It serves a clear function: \"just the facts\" about corporate fundamentals.\n",
        "\n",
        "Cluster 1 – Possibly Too Broad\n",
        "\n",
        "Why? It groups both general investment advice (e.g., retirement strategies, “buy now” lists) and specific stock analyses (e.g., AMAT, ANSS). While these all relate to stock picking and personal finance, the range of topics spans dividend investing, AI growth investing, and value strategies.\n",
        "Result: It’s topically coherent around \"what to buy and why\", but the diversity of tone and stock types (tech, energy, value) risks making this cluster slightly too broad.\n",
        "\n",
        "Cluster 2 – Broad in Topic, Specific in Type\n",
        "\n",
        "Why? While the news stories range from tariffs and legal settlements to AI industry battles and FDA policy, they all share a macro or event-driven tone. This is more of a “market-moving news” cluster.\n",
        "Result: It's a well-scoped thematic cluster (macro/news), but broad in topic area because it aggregates different sectors and event types (legal, regulatory, geopolitical)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf856488",
      "metadata": {
        "id": "cf856488"
      },
      "source": [
        "#### What role does PCA play in the visualization step? Why do we reduce to two dimensions, and what is lost in doing so?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0253e5c0",
      "metadata": {
        "id": "0253e5c0"
      },
      "source": [
        "YOUR WRITTEN RESPONSE HERE\n",
        "\n",
        "PCA (Principal Component Analysis) reduces the high-dimensional embedding vectors into 2D for visualization. This helps us observe general clustering trends. However, reducing to two dimensions loses a lot of the original structure and subtle distinctions, potentially flattening separable clusters into overlapping visual regions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c42f507",
      "metadata": {
        "id": "2c42f507"
      },
      "source": [
        "### Critical Thinking"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5045a46",
      "metadata": {
        "id": "b5045a46"
      },
      "source": [
        "#### What are some limitations of this analysis approach in a real-world financial setting?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "824d9258",
      "metadata": {
        "id": "824d9258"
      },
      "source": [
        "YOUR WRITTEN RESPONSE HERE\n",
        "\n",
        "News coverage is uneven: Not all stocks have news at all times.\n",
        "Embeddings may not capture financial nuance or factual correctness.\n",
        "No temporal modeling — the pipeline ignores when the news was released and how recent it is.\n",
        "No sentiment or price impact assessment is done, which are critical in finance.\n",
        "Embedding models are not fine-tuned on financial data, which may lead to shallow understanding of domain-specific terms."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5398ba7",
      "metadata": {
        "id": "c5398ba7"
      },
      "source": [
        "#### If you had access to more detailed news metadata (e.g., sentiment, category, author), how might you integrate that into your clustering pipeline?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "796eb1a1",
      "metadata": {
        "id": "796eb1a1"
      },
      "source": [
        "YOUR WRITTEN RESPONSE HERE\n",
        "\n",
        "You could:\n",
        "- Add sentiment as an extra feature vector (or embed it directly).\n",
        "- Filter or cluster separately by categories (e.g., legal, earnings).\n",
        "- Group by author or source credibility to assess bias or quality.\n",
        "- Use metadata to weight or filter certain types of news in training."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b703fac4",
      "metadata": {
        "id": "b703fac4"
      },
      "source": [
        "#### Suppose you're tasked with building a news recommendation engine using this embedding and clustering method. What would be your next steps?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a307b0d",
      "metadata": {
        "id": "8a307b0d"
      },
      "source": [
        "YOUR WRITTEN RESPONSE HERE\n",
        "\n",
        "- Assign users or stocks their own embedding vector based on interaction or price response history.\n",
        "- Use cosine similarity between user vector and news embeddings to recommend top-k items.\n",
        "- Incorporate time decay (recent news is weighted more).\n",
        "- Continuously update clustering to adapt to new patterns.\n",
        "- Add user feedback to fine-tune relevance."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}